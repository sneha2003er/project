{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOL5eQXzhWfOVZer66sEvQm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sneha2003er/project/blob/main/oversampling_of_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wka55_URpfTA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt1m_76rpoMy",
        "outputId": "d1fdc247-7291-4ef9-c8bb-050d585ed4b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "import random"
      ],
      "metadata": {
        "id": "PH7vazqi9EoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_directory = '/content/drive/MyDrive/data/dataset'\n",
        "video_directory = os.path.join(base_directory, 'video_data')\n",
        "img_directory = os.path.join(base_directory, 'img_data')"
      ],
      "metadata": {
        "id": "2Pj5mhas92if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames_from_video(video_path, output_dir, rate=1):\n",
        "    \"\"\"Extract frames from a video and save them to an output directory.\"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    vidcap = cv2.VideoCapture(video_path)\n",
        "    fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    success, image = vidcap.read()\n",
        "    count = 0\n",
        "    frame_count = 0\n",
        "\n",
        "    while success:\n",
        "        if count % (fps // rate) == 0:  # Extract every (fps/rate) frame\n",
        "            frame_name = os.path.join(output_dir, f\"frame_from_video_{frame_count}.jpg\")\n",
        "            cv2.imwrite(frame_name, image)\n",
        "            frame_count += 1\n",
        "\n",
        "        success, image = vidcap.read()\n",
        "        count += 1\n",
        "\n",
        "    vidcap.release()\n",
        "\n"
      ],
      "metadata": {
        "id": "SWXk4_YAxGJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data_type in ['train_videos', 'test_videos']:  # Updated directory names here\n",
        "    current_video_dir = os.path.join(video_directory, data_type)\n",
        "    current_img_output_dir = os.path.join(img_directory, data_type.replace('_videos', ''), 'extracted_from_videos')  # Adjusting the output directory to match img_data structure\n",
        "\n",
        "    if os.path.exists(current_video_dir):\n",
        "        for video_file in os.listdir(current_video_dir):\n",
        "            video_path = os.path.join(current_video_dir, video_file)\n",
        "            extract_frames_from_video(video_path, current_img_output_dir)\n",
        "    else:\n",
        "        print(f\"Directory not found: {current_video_dir}\")"
      ],
      "metadata": {
        "id": "Fed8ZcjL0T6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the directory counts to determine the class with most samples\n",
        "class_counts = {cls: len(os.listdir(os.path.join(img_directory, 'train', cls))) for cls in ['default', 'extracted_from_videos', 'fire', 'smoke']}\n",
        "max_samples = max(class_counts.values())\n",
        "print(\"Class counts before oversampling:\", class_counts)"
      ],
      "metadata": {
        "id": "ZbjbvxCd4Dxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56dad5ee-bfb5-4e6b-9fd2-6aa01b38df16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts before oversampling: {'default': 161, 'extracted_from_videos': 437, 'fire': 274, 'smoke': 258}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def oversample_class(data_dir, class_name, target_samples, datagen):\n",
        "    \"\"\"Oversample a class using data augmentation.\"\"\"\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    images = [os.path.join(class_dir, img_file) for img_file in os.listdir(class_dir)]\n",
        "\n",
        "    while len(os.listdir(class_dir)) < target_samples:\n",
        "        # Randomly choose an image from the class directory\n",
        "        chosen_image = random.choice(images)\n",
        "        img = load_img(chosen_image)\n",
        "        x = img_to_array(img)\n",
        "        x = x.reshape((1,) + x.shape)\n",
        "\n",
        "        # Generate augmented images until we reach the target samples for the class\n",
        "        for batch in datagen.flow(x, batch_size=1, save_to_dir=class_dir, save_prefix='aug', save_format='jpg'):\n",
        "            break  # We only need one augmented image per chosen image, so break after the first batch.\n",
        "\n",
        "# Set up data augmentation configuration\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Oversample each class to match the majority class\n",
        "train_data_dir = os.path.join(img_directory, 'train')\n",
        "for cls in ['default', 'extracted_from_videos', 'fire', 'smoke']:\n",
        "    current_class_samples = len(os.listdir(os.path.join(train_data_dir, cls)))\n",
        "    if current_class_samples < max_samples:\n",
        "        oversample_class(train_data_dir, cls, max_samples, datagen)\n",
        "\n",
        "# Check class distribution after oversampling\n",
        "class_counts_after = {cls: len(os.listdir(os.path.join(img_directory, 'train', cls))) for cls in ['default', 'extracted_from_videos', 'fire', 'smoke']}\n",
        "print(\"Class counts after oversampling:\", class_counts_after)\n"
      ],
      "metadata": {
        "id": "vP6rtss94J4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d6a31e-6142-4ba3-fa23-4eb1e48b077c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts after oversampling: {'default': 437, 'extracted_from_videos': 437, 'fire': 437, 'smoke': 437}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the directory counts to determine the class with most samples\n",
        "class_counts = {cls: len(os.listdir(os.path.join(img_directory, 'test', cls))) for cls in ['default', 'extracted_from_videos', 'fire', 'smoke']}\n",
        "max_samples = max(class_counts.values())\n",
        "print(\"Class counts before oversampling:\", class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHmES-oSER6x",
        "outputId": "9ce8f292-82bc-4599-a21c-8bbe0eb3d2f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts before oversampling: {'default': 84, 'extracted_from_videos': 65, 'fire': 57, 'smoke': 30}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversample each class to match the majority class\n",
        "train_data_dir = os.path.join(img_directory, 'test')\n",
        "for cls in ['default', 'extracted_from_videos', 'fire', 'smoke']:\n",
        "    current_class_samples = len(os.listdir(os.path.join(train_data_dir, cls)))\n",
        "    if current_class_samples < max_samples:\n",
        "        oversample_class(train_data_dir, cls, max_samples, datagen)"
      ],
      "metadata": {
        "id": "S-_mr72-Ezw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class distribution after oversampling\n",
        "class_counts_after = {cls: len(os.listdir(os.path.join(img_directory, 'test', cls))) for cls in ['default', 'extracted_from_videos', 'fire', 'smoke']}\n",
        "print(\"Class counts after oversampling:\", class_counts_after)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI858V7XEl4X",
        "outputId": "94df3450-1137-49ec-d643-39e11084b0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts after oversampling: {'default': 84, 'extracted_from_videos': 84, 'fire': 84, 'smoke': 84}\n"
          ]
        }
      ]
    }
  ]
}